\documentclass[fleqn,usenatbib]{mnras}

% MNRAS is set in Times font. If you don't have this installed (most LaTeX
% installations will be fine) or prefer the old Computer Modern fonts, comment
% out the following line
%\usepackage{newtxtext,newtxmath}
\usepackage{times}
% Depending on your LaTeX fonts installation, you might get better results with one of these:
% \usepackage{mathptmx}
% \usepackage{txfonts}

% Use vector fonts, so it zooms properly in on-screen viewing software
% Don't change these lines unless you know what you are doing
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}


%%%%% AUTHORS - PLACE YOUR OWN PACKAGES HERE %%%%%
%\usepackage{epsf}
\usepackage{color}
\usepackage{graphicx}
\usepackage{amsmath}	% Advanced maths commands
\usepackage{amssymb}	% Extra maths symbols
\usepackage{mathrsfs}	% Extra extra math symbols
\usepackage{natbib}
%\usepackage[colorlinks,urlcolor=magenta,citecolor=blue,linkcolor=blue]{hyperref}
\usepackage{multirow}
\usepackage{etoolbox}
\usepackage{listings}

\graphicspath{{./figures/}}

%%%%% AUTHORS - PLACE YOUR OWN COMMANDS HERE %%%%%
%%% Filters %%%
\newcommand{\sdssu}{\hbox{$u$}}
\newcommand{\sdssg}{\hbox{$g$}}
\newcommand{\sdssr}{\hbox{$r$}}
\newcommand{\sdssi}{\hbox{$i$}}
\newcommand{\sdssz}{\hbox{$z$}}

%%% Astronomy Abreviations %%%
\newcommand{\mstar}{\hbox{$M_{\star}$}}
\newcommand{\lstar}{\hbox{L$_{\star}$}}
\newcommand{\Msol}{\hbox{$M_\odot$}}
\newcommand{\msol}{\hbox{$M_\odot$}}
\newcommand{\Zsol}{\hbox{$Z_\odot$}}
\newcommand{\zsol}{\hbox{$Z_\odot$}}

%%% Units %%%
\newcommand{\kms}{\hbox{km~s$^{-1}$}}
\newcommand{\cms}{\hbox{cm~s$^{-1}$}}
\newcommand{\degree}{\hbox{$^\circ$}}
\newcommand{\degsq}{\hbox{degree$^2$}}
\newcommand{\arcminsq}{\hbox{arcmin$^2$}}
\newcommand{\um}{\hbox{$\mu$m}}

%%% per Units %%%
\newcommand{\perarcminsq}{\hbox{arcmin$^{-2}$}}
\newcommand{\perdegsq}{\hbox{degree$^{-2}$}}
\newcommand{\permpc}{\hbox{Mpc$^{-1}$}}
\newcommand{\permpcsq}{\hbox{Mpc$^{-2}$}}
\newcommand{\permpccu}{\hbox{Mpc$^{-3}$}}
\newcommand{\percmsq}{\hbox{cm$^{-2}$}}
\newcommand{\percmcu}{\hbox{cm$^{-3}$}}
\newcommand{\perpixel}{\hbox{pixel$^{-1}$}}

%%% General %%%
\newcommand{\eg}{e.g.}
\newcommand{\ie}{i.e.}
\newcommand{\citeeg}[1]{(\eg, \citealt{#1})}
\newcommand{\editorial}[1]{\textcolor{red}{#1}}

%%%%%%%%%%%%%%%%%%% TITLE PAGE %%%%%%%%%%%%%%%%%%%
\title[Galaxy metallicity with CNNs]{Using convolutional neural networks to predict galaxy metallicity from three-color images}

% The list of authors, and the short list which is used in the headers.
% If you need two or more lines of authors, add an extra line using \newauthor
\author[Wu and Boada]
{\parbox{\textwidth}{John~F.~Wu$^{1}$\thanks{E-mail: \href{mailto:jw740@physics.rutgers.edu}} and
Steven~Boada$^{1}$}\vspace{0.4cm}\
\\
\parbox{\textwidth}{$^{1}$Department of Physics and Astronomy, Rutgers, The State University of New Jersey, 136 Frelinghuysen Road, Piscataway, NJ 08854-8019, USA\\}}

% These dates will be filled out by the publisher
\date{Accepted XXX. Received YYY; in original form ZZZ}

% Enter the current year, for the copyright statements etc.
\pubyear{2018}

% Don't change these lines
\begin{document}
\label{firstpage}
\pagerange{\pageref{firstpage}--\pageref{lastpage}}
\maketitle

\begin{abstract}
We train a deep residual convolutional neural network (CNN) to predict the gas-phase metallicity ($Z$) of galaxies derived from spectroscopic information ($Z \equiv 12 + \log(\rm O/H)$) using only three-band \sdssg\sdssr\sdssi\ images from the Sloan Digital Sky Survey. When trained and tested on $128 \times 128$-pixel images, the root mean squared error (RMSE) of $Z_{\rm pred} - Z_{\rm true}$ is only 0.085~dex, vastly outperforming a trained random forest algorithm on the same data set (RMSE $=0.130$~dex). The amount of scatter in $Z_{\rm pred} - Z_{\rm true}$ decreases with increasing image resolution in an intuitive manner. We are able to use CNN-predicted $Z_{\rm pred}$ and independently measured stellar masses to recover a mass-metallicity relation with $0.10$~dex scatter. Because our predicted MZR shows no more scatter than the empirical MZR, the difference between $Z_{\rm pred}$ and $Z_{\rm true}$ can not be due to purely random error. This suggests that the CNN has learned a representation of the gas-phase metallicity, from the optical imaging, beyond what is accessible with oxygen spectral lines.
\end{abstract}

\section{Introduction}\label{sec:introduction}
Large-area sky surveys, both on-going and planned, are revolutionizing our understanding of galaxy evolution. The Dark Energy Survey (DES; \citealt{DES2005}) and upcoming Large Synoptic Survey Telescope (LSST; \citealt{LSST2012}) will scan vast swaths of the sky and create samples of galaxies of unprecedented size. Spectroscopic follow-up of these samples will be instrumental in order to understand their properties. Previously, the Sloan Digital Sky Survey \citep[SDSS;][]{York2000} and its spectroscopic campaign enabled characterization of the mass-metallicity relation (hereafter MZR; \citealt{Tremonti2004}) and the fundamental metallicity relation, (hereafter FMR; \eg, \citealt{Mannucci2010}). As future surveys are accompanied by larger data sets, individual spectroscopic follow-up observations will become increasingly impractical.

Fortunately, the large imaging data sets to be produced are ripe for application of machine learing (ML) methods. ML is already showing promise in studies of galaxy morphology \citeeg{Dieleman2015, Huertas-Company2015, Beck2018, Dai2018, Hocking2018}, gravitational lensing \citeeg{Hezaveh2017, Lanusse2017, Petrillo2017, Petrillo2018}, galaxy clusters \citeeg{Ntampaka2015, Ntampaka2016}, star-galaxy separation \citeeg{Kim2017}, creating mock galaxy catalogs \citeeg{Xu2013}, and asteroid identification \citeeg{Smirnov2017}, among many others. ML methods utilizing neural networks have grown to prominence in recent years. While neural networks are a relatively old technique \citeeg{LeCun1989}, their recent increase in popularity is driven by the widespread availability of affordable graphics processing units (GPUs), that can be used to do general purpose, highly parallel computing. Also, unlike more ``traditional'' ML methods, neural networks excel at image classification and regression problems.

Inferring spectroscopic properties from the imaging taken as part of a large-area photometric survey is, at a basic level, an image regression problem. These problems are most readily solved by use of convolutions in multiple layers of the network (see, \eg, \citealt{Krizhevsky2012}). Convolutional neural networks (CNNs, or convnets) efficiently learn spatial relations in images whose features are about the same sizes as the convolution filters (or kernels) that are to be learned through training. CNNs are considered \textit{deep} when the number of convolutional layers is large. Visualizing their filters reveals that increased depth permits the network to learn more and more abstract features (\eg, from Gabor filters, to geometric shapes, to faces; \citealt{Zeiler2014}).

In this work, we propose to use supervised ML by training CNNs to analyze pseudo-three color images and predict the gas-phase metallicity. We use predicted metallicities to recover the empirical \cite{Tremonti2004} MZR. This paper is organized as follows: In Section~\ref{sec:data}, we describe the acquisition and cleaning of the SDSS data sample. In Section~\ref{sec:training}, we discuss selection of the network's hyperparameters and outline training the of network. We present the main results in Section~\ref{sec:results} and discuss our findings in the context of current literature. In Section~\ref{sec:MZR}, we interpret the MZR using the metallicity predicted by our CNN. We summarize our key results and discuss possible future work in Section~\ref{sec:summary}.

Unless otherwise noted, throughout this paper, we use a concordance cosmological model ($\Omega_\Lambda = 0.7$, $\Omega_m = 0.3$, and $H_0= 70$ \kms{} \permpc), assume a Kroupa initial mass function \citep{Kroupa2001}, and use AB magnitudes \citep{Oke1974}.

\section{Data} \label{sec:data}
To create a large training sample, we select galaxies from the Sloan Digital Sky Survey (SDSS; \citealt{York2000}) DR7 MPA/JHU spectroscopic catalog \citep{Kauffmann2003a, Brinchmann2004, Tremonti2004, Salim2007}. The catalog provides spectroscopically derived properties such as stellar mass (\mstar) and gas-phase metallicity ($Z$) estimates \citep{Tremonti2004}. We select objects with low reduced chi-squared of model fits (\texttt{rChi2} $< 2$), and median $Z$ estimates available (\texttt{oh\_p50}). We supplement the data from the spectroscopic catalog with photometry in each of the five SDSS photometric bands (\sdssu, \sdssg, \sdssr, \sdssi, \sdssz), along with associated errors from SDSS DR14 \citep{Abolfathi2017}.

We require that galaxies magnitudes are $10 < \sdssu \sdssg \sdssr \sdssi \sdssz < 25$ mag, in order to avoid saturated and low signal-to-noise detections. We enforce a color cut, $0 < \sdssu-\sdssr < 6$, in order to avoid extremely blue or extremely red objects, and require objects to have spectroscopic redshifts greater than $z=0.02$ with low errors ($z_{err} < 0.01$). The median redshift is $0.07$ and the highest-redshift object has $z = 0.38$. We also require that the \sdssr-band magnitude measured inside the Petrosian radius (\texttt{petroMag\_r}; \citealt{Petrosian1976}) be less than 18 mag, corresponding to the spectroscopic flux limit. With these conditions we construct an initial sample of 142,182 objects (there are four objects with duplicate SDSS DR14 identifiers).
We set aside 25,000 objects for later testing, and use the rest for training and validation.

We create RGB image cutouts of each galaxy with the SDSS cutout service\footnote{\url{http://skyserver.sdss.org/dr14/en/help/docs/api.aspx}}, which converts \sdssg\sdssr\sdssi\ bands to RGB channels according to the algorithm described in \cite{Lupton2004} (with modifications by the SDSS SkyServer team). Since images are not always available, we are left with 116,429 SDSS images with metallicity measurements, including 20,466/25,000 of the test subsample. We create $128\times128$-pixel JPG images with a pixel scale of $0\farcs296$, which corresponds to $38''\times 38''$ on the sky.  We do not further preprocess, clean, or filter the images before using them as inputs to our CNN.

\section{Methodology}\label{sec:training}
%The input layer is simply an image of $128\times 128$ pixels with three channels (RGB).
Before the CNN can be asked to make predictions, it must be trained to learn the relationships between the input data (the images described above) and the desired output (metallicity). The CNN makes predictions using the input images, and the error (or loss) is determined based on the differences between true and predicted values. The CNN then updates its parameters, or weights, in a way that minimizes the loss function. We use the root mean squared error loss function:
\begin{equation}
\mathrm{RMSE} \equiv \sqrt{\langle |y_{\rm true} - y_{\rm pred}|^2\rangle},
\end{equation}
where $y_{\rm true}$ is the ``true'' and $y_{\rm pred}$ is the predicted value, and $y$ represents the target quantity. It is worth emphasizing that the $Z_{\rm true}$ is the \textit{observed} metallicity estimated from SDSS spectra using the $R_{23}$ method, but for the purpose of training the network, we label the observed metallicity as the \textit{true} metallicity. We define $Z_{\rm true}$ to be the 50th percentile metallicity estimated by \cite{Tremonti2004}.

We randomly split our training sample of $\sim 96,953$ images into 80\% (76,711) training and 20\% (19,192) validation data sets, respectively. The test data set of 20,466 images is isolated for now, and is not accessible to the CNN until all training is completed. Images and $Z_{\rm true}$ answers are given to the CNN in ``batches'' of 256 at a time, until the full training data set has been used for training. Each full round of training using all of the data is called an epoch, and we compute the loss using the validation data set at the end of each epoch.
We use gradient descent for each batch to adjust weight parameters, and each weight's fractional contribution of loss is determined by the backpropagation algorithm \citep{LeCun1989}, during which finite partial derivatives are computed and propagated backwards through layers (i.e., using the chain rule for derivatives).

We use a 34-layer residual CNN architecture \citep{He2015}, initialized to weights pre-trained on the ImageNet data set, which consists of 1.7 million images belonging to 1000 categories of objects found on Earth \citep[e.g., cats, horses, cars, or books;][]{ImageNet}.
The CNN is trained for a total of 10 epochs.
For more details about the CNN architecture, transfer learning, hyperparameter selection, data augmentation, and the training process, see the Appendix.
In total, our training process requires 25-30 minutes on our GPU and uses under 2~GB of memory.

We evaluate predictions using the RMSE loss function, which approaches the standard deviation for Gaussian-distributed data.
We also report the NMAD, or the normal median absolute deviation \citeeg{Ilbert2009, Dahlen2013, Molino2017}:
\begin{equation}
{\rm NMAD}(x) \approx 1.4826 \times {\rm median} \big (\big|x - {\rm median }(x) \big|\big ),
\end{equation}
where for a Gaussian-distributed $x$, the NMAD will also approximate the standard deviation, $\sigma$.
NMAD has the distinct advantage in that it is insensitive to outliers and can be useful for measuring scatter.
However, unlike the RMSE, which quantifies the typical scatter distributed about a center of zero, NMAD only describes the scatter around the (potentially non-zero) median.

\section{Results}\label{sec:results}

\subsection{Example predictions}
\begin{figure*}
	\includegraphics[width=0.9\textwidth]{01-prediction_examples.pdf}
	\caption{\label{fig:examples}
		SDSS imaging with predicted and true metallicities from the test data set. Five examples are shown from each of the following categories: (a) lowest predicted metallicity, (b) lowest true metallicity, (c) highest predicted metallicity, (d) highest true metallicity, (e) most under-predicted metallicity, (f) most over-predicted metallicity, and (g) a set of randomly selected galaxies.}
\end{figure*}

In Figure~\ref{fig:examples}, we show examples of $128 \times 128$ pixel \sdssg\sdssr\sdssi\ SDSS images that are evaluated by the CNN. Rows (a) and (b) depict the galaxies with lowest predicted and lowest true metallicities, respectively. The CNN associates blue, edge-on disk galaxies with low metallicities, and is generally accurate in its predictions. In rows (c) and (d), we show the galaxies with highest predicted and highest true metallicities, respectively. Here we find that red galaxies containing prominent nuclei are predicted to be high in metallicity, and that their predictions generally match $Z_{\rm true}$.

Galaxies predicted by our CNN to have high metallicities ($Z_{\rm pred} > 9.0$) tend to be characterized by high $Z_{\rm true}$, and the equivalent is true for low-metallicity galaxies. Conversely, galaxies with the highest (lowest) \textit{true} metallicities in the sample are also predicted to have high (low) metallicities. Note that inclined galaxies tend to be lower in metallicity whereas face-on galaxies appear to be higher in metallicity. \cite{Tremonti2004} explain this correlation by suggesting that the SDSS fiber aperture captures more column of a projected edge-on disk, allowing the metal-poor, gas-rich, and less-extincted outer regions to more easily be detected and depress the integrated $Z_{\rm true}$.

We will now consider examples of the most incorrectly predicted galaxies. In rows (e) and (f), we show instances in which the CNN predicted too low metallicity and too high metallicity, respectively. The two galaxies with the most negative residuals $\Delta Z \equiv Z_{\rm pred} - Z_{\rm true}$ (\ie, most under-predicted metallicities) suffer from artifacts that cause unphysical color gradients, and/or are labeled as quasars on the basis of their SDSS spectra (for which we expect $Z_{\rm true}$ to be biased). It is not unsurprising that the CNN has made mistakes in some of these cases, since they go against astronomers' usual heuristics: blue, disk-dominated sources are generally thought of as lower in metallicity, and redder, more spheroidal objects tend to be higher in metallicity.

In the bottom row (g) of Figure~\ref{fig:examples}, we show five randomly selected galaxies. The random SDSS assortment consists of lenticular, spiral, and possibly even an interacting pair of galaxies. Residuals are low (below 0.15~dex), and we again find that the CNN predictions track with human visual intuition.

\subsection{Comparing predicted and true metallicities}
\begin{figure}
	\includegraphics[width=\columnwidth]{03-Z_distribution.pdf}
	\caption{\label{fig:distributions}
		Distributions of the true (black) and predicted (red) galaxy metallicities. Note that the bin widths are different for the two distributions. See text for details.}
\end{figure}

In Figure~\ref{fig:distributions}, we show histograms of the true and predicted metallicities in black and red, respectively. The histogram bin sizes are chosen according to the \cite{Freedman1981} rule for each distribution. The discreet striping of the \cite{Tremonti2004} and \cite{Brinchmann2004} metallicity estimator appears in the $Z_{\rm true}$ distribution but does not appear in our CNN predictions. This striping should increase the scatter in our distribution of residuals.

The range of $Z_{\rm pred}$ is more limited than the range of $Z_{\rm true}$, which can also be seen from Figure~\ref{fig:examples} for extremal values of $Z_{\rm true}$. Too narrow a domain in $Z_{\rm pred}$ will lead to systematic errors, as the CNN will end up never predicting very high or very low metallicities. Although the two distributions are qualitatively consistent with each other at low metallicities (\eg, $Z < 8.5$), the fraction of galaxies with high $Z_{\rm true} > 9.1$ ($2573/20466 = 12.6\%$) is higher than the fraction with high $Z_{\rm pred} > 9.1$ ($1174/20466 = 5.7\%$).


We find that the mode of the binned predicted metallicity distribution is higher than that of $Z_{\rm true}$. This result may be a consequence of the CNN overcompensating for its systematic under-prediction of metallicity for galaxies with $Z_{\rm true} > 9.1$. However, its effect on the entire distribution is small, and may be remedied simply by increasing the relative fraction of very high-$Z_{\rm true}$ objects. We find overall good qualitative agreement between the $Z_{\rm pred}$ and $Z_{\rm true}$ distributions.

\subsection{Scatter in $Z_{\rm pred}$ and $Z_{\rm true}$}
\begin{figure}
	\includegraphics[width=\columnwidth]{02-prediction_summary.pdf}
	\caption{\label{fig:predicting-metallicity}
		Bivariate distribution of true galaxy metallicity ($Z_{\rm true}$) and CNN prediction ($Z_{\rm pred}$) is shown in the main panel. Overlaid are the median predicted metallicity (solid red line), RMSE scatter (dashed red lines), and NMAD scatter (dashed violet lines), in bins of $Z_{\rm true}$. The solid black line shows the one-to-one relation. The distribution of residuals ($Z_{\rm pred} - Z_{\rm true}$) is shown in the inset plot. In the upper panel, we again show the binned scatter, where the size of each marker is proportional to the number of galaxies in that bin. Each horizontal line corresponds to the average scatter over the entire test data set (and the global value indicated in the upper panel legend).}
\end{figure}

In Figure~\ref{fig:predicting-metallicity}, we compare the distributions of $Z_{\rm true}$ and $Z_{\rm pred}$ using a two-dimensional histogram (shown in grayscale in the main, larger panel). We also show the median predictions varying with binned $Z_{\rm true}$ (solid red line), in addition to the scatter in RMSE (dashed red) and NMAD (dashed violet), and also the one-to-one line (solid black). The running median agrees well with the one-to-one line, although at low metallicity we find that the CNN makes makes overpredictions.

A histogram of metallicity residuals is shown in the inset plot of the Figure~\ref{fig:predicting-metallicity} main panel. The $\Delta Z$ distribution is characterized by an approximately normal distribution with a heavy tail at large positive residuals; this heavy tail is likely due to the systematic over-prediction for low-$Z_{\rm true}$ galaxies.
There is also an overabundance of large negative $\Delta Z$ corresponding to under-predictions for high $Z_{\rm true}$, although this effect is smaller.

We now turn our attention to the upper panel of Figure~\ref{fig:predicting-metallicity}, which shows how the scatter varies with spectroscopically derived metallicity. The RMSE scatter and outlier-insensitive NMAD are both shown. Marker sizes are proportional in area to the number of samples in each $Z_{\rm true}$ bin, and the horizontal lines are located at the average loss (RMSE or NMAD) for the full test data set.

Predictions appear to be both accurate and low in scatter for galaxies with $Z_{\rm true} \approx 9.0$, which is representative of a typical metallicity in the SDSS sample. Where the predictions are systematically incorrect, we find that the RMSE increases dramatically. However, the same is not true for the NMAD; at $Z_{\rm true} < 8.5$, it asymptotes to $\sim 0.10$~dex, even though the running median is incorrect by approximately the same amount! This discrepancy is because the NMAD determines the scatter about the \textit{median} and not $\Delta Z = 0$, and thus, this metric becomes somewhat unreliable when the binned samples do not have a median value close to zero. Fortunately, the global median of $\Delta Z$ is $-0.006$~dex, or less than 10\% of the RMSE, and thus the global NMAD $= 0.067$~dex is representative of the outlier-insensitive scatter for the entire test data set.

This effect partly explains why the global NMAD ($0.067$~dex) is higher than the weighted average of the binned NMAD ($\sim 0.05$~dex). Also, each binned NMAD is computed using its local scatter, such that the outlier rejection criterion varies with $Z_{\rm true}$. To illustrate this effect with an example: $\Delta Z \approx 0.2$~dex would be treated as an $3\,\sigma$ outlier at $Z_{\rm true} = 9.0$, where the CNN is generally accurate, but the same residual would not be rejected as an outlier using NMAD for $Z_{\rm true} = 8.5$.
Since the binned average NMAD depends on choice of bin size, we do not include those results in our analysis and only focus on the global NMAD.
RMSE is a robust measure of both local and global scatter (although it becomes biased high by outliers).

\subsection{Resolution effects} \label{sec:resolution}
%Note by the way that our CNN trained on color images is able to predict better than by using only photometry (via random forest) and morphology ($r$-band CNN) independently.
%Perhaps this is due to the fact that morphology is correlated with stellar population age or something else.
%Color tells us the fundamental plane of SFR-$M_*$-metallicity but is biased by age and dust.

\begin{figure}
	\includegraphics[width=\columnwidth]{04-resolution.pdf}
	\caption{\label{fig:resolution}
		The effects of image resolution on CNN performance. Red and violet circular markers indicate scatter in the residual distribution ($\Delta Z$) measured using RMSE and NMAD, respectively. (Each point is analogous to the horizontal lines shown in Figure~\ref{fig:predicting-metallicity}.) We also show predictions from a random forest algorithm as open triangle markers, and constant $\langle Z_{\rm true}\rangle$ predictions as open square markers.}
\end{figure}

Because our methodology is so computationally light, we can run the same CNN training and test procedure on images scaled to different sizes in order to understand the effects of image resolution. Our initial results use SDSS $38\arcsec \times 38 \arcsec$ cutouts resized to $128\times 128$ pixels, and we now downsample the same images to $64\times 64$, $32 \times 32$, $\cdots$, $2\times 2$, and even $1\times 1$ pixels via re-binning. All images retain their three channels, so the smallest $1 \times 1$ image is effectively the pixels in each of the \sdssg\sdssr\sdssi\ bands averaged together with the background and possible neighboring sources.

In Figure~\ref{fig:resolution}, we show the effects of image resolution by measuring the global scatter in $\Delta Z$ using the RMSE and NMAD metrics (shown in red and violet circular markers, respectively). Also shown is the scatter in $\Delta Z$ if we always predict the mean value of $Z_{\rm true}$ over the data set (shown using a square marker). This constant prediction effectively delivers the worst possible scatter, and the \cite{Tremonti2004} systematic uncertainty in $Z_{\rm true}$ of $\sim 0.03$~dex yields the best possible scatter. We find that both RMSE and NMAD decrease with increasing resolution, as expected if morphology or color gradients are instrumental to predicting metallicity.
%In nearly all cases, we find that the NMAD is lower than the RMSE by a factor of $\sim 3/4$.

There appears to be little improvement in scatter going from $1 \times 1$ to $2\times 2$ pixel images. $1\times 1$ three-color images contain similar information to three photometric data points (although because background and neighboring pixels are averaged in, they are less information-dense than photometry), which can be used to perform a crude spectral energy distribution (SED) fit. Therefore it unsurprising that the $1 \times 1$ CNN predictions perform so much better than the baseline mean prediction. A $2 \times 2$ three-color image contains four times as many pixels as a $1\times 1$ image, but because the object is centered between all four pixels, information is still averaged among all available pixels. Therefore, the scatter does not improve appreciably going from $1 \times 1$ to $2 \times 2$ resolution.\footnote{There is extra information in the $2\times 2$ pixel images in non-circularly symmetric cases. For an inclined disk, it is possible to roughly determine the orientation in the sky plane, but this information is not very useful. In the case of a major merger or interacting companion, the $2\times 2$ images may be more powerful than $1 \times 1$ images.}

The scatter is a strong function of resolution as the images are resolved from $2 \times 2$ to about $32 \times 32$ pixels. With further increasing resolution, improvement is still evident, although the scaling with scatter is noticeably weaker. Because the angular size of each image cutout stays the same, the pixel scale changes from $1\farcs184$ \perpixel\ for $32 \times 32$ images, to $0\farcs592$ \perpixel\ for $64 \times 64$ images, to $0\farcs296$ \perpixel\ for $128 \times 128$ images. The native SDSS pixel resolution is $0\farcs396$ \perpixel, such that the $64 \times 64$ and $128 \times 128$ resolutions result in the oversampling of each image. Thus, scatter is expected to plateau for images larger than $128 \times 128$. It is worth noting, however, that the CNN attempts to learn filters that depend on the size of the input image, so smaller images may result in the CNN training filters that are too low in resolution to be completely effective for prediction. Therefore, it is also not surprising that the CNN makes incremental gains for images with increasing resolution beyond $64 \times 64$ pixels.

\subsection{Random forest predictions for metallicity}
We also construct a random forest (RF) of decision trees in order to predict metallicity using the implementation from \texttt{scikit-learn} \citep{Pedregosa2012}. Hyperparameters are selected according to the optimal RF trained by \cite{Acquaviva2016}. We use exactly the same data labels (\ie, galaxies) to train/validate or test the RF that we have used for training and testing the CNN, so that our measurements of scatter can be directly compared. However, we have used the \sdssg\sdssr\sdssi\ three-band photometry data (given in magnitudes) to train and predict metallicity. Since each galaxy only has three pieces of photometric information, it can be compared to the $1 \times 1$ three-band ``images'' processed by our CNN.

The RF predicts metallicity with RMSE $= 0.130$~dex, which is superior to our CNN trained and tested on $1\times 1$ and $2 \times 2$ images. This result is unsurprising because the RF is supplied aperture-corrected photometry, whereas the CNN is provided $1 \times 1 $ \sdssg\sdssr\sdssi\ ``images'' whose features have been averaged with their backgrounds. $2 \times 2$ images are only marginally more informative. When the resolution is further increased to $4 \times 4$ images, then the CNN can begin to learn rough morphological features and color gradients, which is already enough to surpass the performance (measured by both RMSE and NMAD) of the RF.
This result suggests that the CNN is able to learn a nontrivial representation of gas-phase metallicity based on three-band brightness distributions, even with extremely low-quality data.

\subsection{Comparisons to previous work}\label{sec:previous work}
CNNs have been used for a wide variety of classification tasks in extragalactic astronomy, including morphological classification \citeeg{Dieleman2015, Huertas-Company2015, 2017MNRAS.464.4420S}, distinguishing between compact and extended objects \citep{Kim2017}, selecting observational samples of rare objects based on simulations \citep{Huertas-Company2018, Lanusse2017}, and visualizing high-level morphological galaxy features \citep{Dai2018}. These works seek to improve classification of objects into a discreet number of classes, \ie, visual morphologies. Our paper uses CNNs to tackle the different problem of regression, \ie, predict values from a continuous distribution.

Examples of regressing stellar properties in the astronomical ML literature \citeeg{2000A&A...357..197B, Fabbro2018} train on synthetic stellar spectra and test on real data. Their predicted measurements of stellar properties, \eg, stellar effective temperature, surface gravity, or elemental abundance, can be derived from the available training data set. Our work is novel because we predict metallicity, a spectroscopically determined galaxy property, using only three-color images. Said another way, it is not necessarily the case that $Z$ can be predicted from our training data. However, we find that galaxy shape supplements color information in a way that is useful for predicting metallicity.

A study similar to this work is that of \cite{Acquaviva2016}, who uses a variety of machine learning methods including RFs, extremely random trees (ERTs), boosted decision trees (AdaBoost), and support vector machines (SVMs) in order to estimate galaxy metallicity. The \cite{Acquaviva2016} data set consisted of a $z \sim 0.1$ sample (with $\sim 25,000$ objects) and a $z \sim 0.2$ sample (with $\sim 3,000$ objects), each of which has five-band SDSS photometry ($ugriz$) available as inputs. These samples are sparsely populated at low metallicities, and they contain smaller fractions of objects with $Z_{\rm true} < 8.5$ than our sample, but are otherwise similarly distributed in $Z_{\rm true}$ to ours. Our samples have different sizes because we require SDSS objects to have imaging available, whereas the \cite{Acquaviva2016} criteria impose stronger spectroscopic redshift constraints.

We will first compare RF results, since this technique is common to both of our analyses, and they reveal important differences in our training data. Because outliers are defined differently in both works, we will use the RMSE metric to compare scatter between the two. \cite{Acquaviva2016} obtain RMSE of 0.081 and 0.093~dex when using RFs on the five-band photometry for the $z \sim 0.1$ and $0.2$ subsamples. Using exactly the same RF approach on a larger sample, while working with only \textit{three} bands of photometric information, we find RMSE $= 0.130$~dex. Our scatter is larger than the value reported by \cite{Acquaviva2016} by a factor of $\sim 1.5\%$. This result may partly be explained by the fact that \cite{Acquaviva2016} $Z_{\rm true}$ distribution is narrower than for our training data set, or the fact that our data set spans a broader range in galaxy redshift; however, some of this advantage is offset by our larger sample size.

Ultimately, it appears that the extra \sdssu\ and \sdssz\ bands supply machine learning algorithms with valuable information for predicting metallicity.

Indeed, the \sdssu\ and \sdssz-bands convey information about a galaxy's SFR and stellar mass \cite[see, e.g.,][]{Hopkins2003}. For this reason, it is possible that the RF trained on five-band photometry can estimate $Z_{\rm true}$ down to the limit of the FMR, which has very small scatter ($\sim 0.05$~dex) at fixed $M_{\star}$ \textit{and} SFR. The \sdssg{}, \sdssr{}, and \sdssi{} bands are less sensitive to the SFR, but can still provide some information about the stellar mass, and so our RF and CNN results are more linked to the MZR rather than the FMR.

Regardless of these limitations, our CNN is able to estimate metallicity with $\Delta Z = 0.085$~dex, which is comparable to the scatter in residuals using the best algorithms from \cite{Acquaviva2016}. There is evidence that the morphological information provided by using images rather than photometric data is helping the CNN perform so well: (1) the RMSE scatter decreases with increasing image resolution, and (2) it identifies edge-on galaxies as lower-$Z_{\rm pred}$ and face-on galaxies as higher-$Z_{\rm pred}$ (consistent with observational bias). Gradients in color, or identification of mergers \citeeg{Ackermann2018} may also be helpful for predicting metallicity.


\section{The mass-metallicity relation} \label{sec:MZR}
The MZR describes the tight correlation between galaxy stellar mass and nebular gas-phase metallicity. Scatter in this correlation is approximately $\sigma \approx 0.10$~dex in $Z_{\rm true}$ over the stellar mass range $8.5 < \log (\mstar / \msol) < 11.5$ \citep{Tremonti2004}, where $\sigma$ is the standard deviation of the metallicity and is equivalent to the RMSE for a normal distribution. The MZR at $z=0$ can be characterized empirically using a polynomial fit:
\begin{equation}\label{eq:mzr}
Z = -1.492 + 1.847 \log (\mstar / \msol) - 0.08026 \left [\log(\mstar / \msol)\right ]^2.
\end{equation}

The physical interpretation of the MZR is that a galaxy's stellar mass strongly correlates with its chemical enrichment. Proposed explanations of this relationship's origin include metal loss through blowout \citep[see, e.g.,][]{2002ApJ...581.1019G,Tremonti2004,Brooks2007,Dave2012}, inflow of pristine gas \cite{Dalcanton2004}, or a combination of the two \citeeg{2013ApJ...772..119L}; however, see also \cite{2013A&A...554A..58S}. Although the exact physical process responsible for the low ($0.10$~dex) scatter in the MZR is not known, its link to SFR via the FMR is clear, as star formation leads to both metal enrichment of the interstellar medium and stellar mass assembly.

The FMR connects the instantaneous ($\sim 10$ Myr) SFR with the gas-phase metallicity \citep[$\sim 1$~Gyr timescales; see, e.g.,][]{2011ApJ...734...48L} and \mstar{} (\ie, the $\sim 13$~Gyr integrated SFR). Our CNN is better suited for predicting \mstar{} rather than SFR, using the \sdssg\sdssr\sdssi bands, which can only weakly probe the blue light from young, massive stars. Therefore, we expect the scatter in CNN predictions to be limited by the MZR (with scatter $\sigma \sim 0.10$~dex) rather than the FMR ($\sigma \sim 0.05$~dex). It is possible that galaxy color and morphology, in tandem with CNN-predicted stellar mass, can be used to roughly estimate the SFR, but in this paper we will focus on only the MZR.


\subsection{Predicting stellar mass}

\begin{figure*}
	\includegraphics[width=\columnwidth]{05-a-prediction_mass.pdf}
	\includegraphics[width=\columnwidth]{05-b-prediction_mzr.pdf}
	\caption{\label{fig:mass-metallicity}
		In the left panel, we plot the CNN predicted galaxy stellar mass against true stellar mass. Colors and marker or line styles are the same as in Figure~\ref{fig:predicting-metallicity}. In the right panel, we compare the predicted stellar mass converted to metallicity, assuming the \citet{Tremonti2004} MZR, against the true metallicity.
		These findings indicate that using the empirical MZR and CNN-predicted $M_{\star,\rm pred}$ yields poor results, unlike what we have observed in Figure~\ref{fig:predicting-metallicity}.
		}
\end{figure*}

Since galaxy stellar mass is known to strongly correlate with metallicity, and is easier to predict (than, \eg, SFR) from \sdssg\sdssr\sdssi\ imaging, we consider the possibility that the CNN is simply predicting stellar mass ($M_{\star,\rm pred}$) accurately and then learning the simple polynomial transformation in order to estimate metallicity. We can simulate this scenario by training the CNN on $M_{\star, \rm true}$ and then converting the stellar mass predictions to metallicities using Equation~\ref{eq:mzr}.

We re-run the CNN methodology to train and predict $M_{\star}$ using the 116,394 available images (out of the 142,145/142,186 original objects that have stellar mass measurements). These results are shown in the left panel of Figure~\ref{fig:mass-metallicity}. From the same subsample as before (minus three objects that do not have \mstar estimates), we verify that $M_{\rm \star, true}$ median agrees with the median of $M_{\rm \star, true}$ for values between $9.0 \lesssim \log \mstar /\msol \lesssim 10.5$. The RMSE scatter in the \mstar{} residuals is $\sim 0.22$~dex, and the NMAD is $\sim 0.20$~dex. The slope of the empirical MZR at $\log (\mstar / \msol) \sim 10$ is (0.4~dex in $Z$)/(1.0~dex in \mstar), implying that the CNN might be able to leverage the MZR and predict metallicity to $\sim 0.08$~dex (plus any intrinsic scatter in the MZR, in quadrature).

We use Equation~\ref{eq:mzr} and $M_{\star,\rm pred}$ to predict metallicity, which we call $Z_{\rm MZR}$. In the right panel of Figure~\ref{fig:mass-metallicity}, we compare $Z_{\rm MZR}$ against $Z_{\rm true}$. The scatter in residuals $Z_{\rm MZR} - Z_{\rm true}$ is $0.12$~dex, which is significantly higher than the $0.085$~dex scatter reported in Section~\ref{sec:results}. If the MZR alone were mediating the CNN's ability to estimate from
\sdssg\sdssr\sdssi\ imaging, then we would expect the scatter for $Z_{\rm pred}$ to be greater than for $Z_{\rm MZR}$; instead we find that the opposite is true. This evidence suggests that the CNN has learned to determine metallicity in a more powerful way than by simply predicting $M_{\rm \star,pred}$ and then effectively applying a polynomial conversion.


\subsection{An unexpectedly strong CNN-predicted mass-metallicity relation}
\begin{figure}
	\includegraphics[width=\columnwidth]{06-mzr.pdf}
	\caption{\label{fig:mzr}
		In the main panel, the predicted MZR comparing true \mstar\ against CNN-predicted $Z_{\rm pred}$ is shown in grayscale. The running median (solid red) and scatter (dashed red and violet) are shown in 0.2~dex mass bins. For comparison, we also show the \citet{Tremonti2004} observed median and scatter (solid and dashed black lines, respectively), which are binned by 0.1~dex in mass. In the upper panel, we show the scatter in the predicted and empirical MZR. The standard deviation of the scatter for the empirical MZR is shown as a dashed black line, while the red and violet circles respectively show RMSE and NMAD for the predicted MZR. Marker sizes are proportional to the number of galaxies in each stellar mass bin for the test data set. Global scatter in the CNN-predicted MZR appears to be comparable to, or even lower than, scatter in the empirical MZR.}
\end{figure}

The RMSE $= 0.085$~dex difference between the true and CNN-predicted metallicities can be interpreted in one of two ways: (1) the CNN is inaccurate, and $Z_{\rm pred}$ deviates randomly from $Z_{\rm true}$, or (2) the CNN is labeling $Z_{\rm pred}$ according to some other hidden variable, and $\Delta Z$ residuals represent non-random shifts in predictions based on this variable. If the first scenario were true, we would expect the random residuals to increase the scatter of other known correlations such as the MZR when predicted by the CNN. If the second were true, we would expect the scatter of such correlations to remain unchanged or shrink. We can therefore contrast the MZR constructed from $Z_{\rm pred}$ and from $Z_{\rm true}$ in order to test these interpretations.

In the main panel of Figure~\ref{fig:mzr}, we plot CNN-predicted metallicity versus true stellar mass. For comparison, we also overlay the \cite{Tremonti2004} MZR median relation and its $\pm 1~\sigma$ scatter (which is $\sim 0.10$~dex). Their empirical median relation (solid black) matches our predicted MZR median (solid red), and the lines marking observed scatter (dashed black) match $Z_{\rm pred}$ scatter as well (dashed red and violet). Over the range $9.5 \leq \log (M_{\star, \rm true}/\msol) \leq 10.5$, the RMSE scatter in $Z_{\rm pred}$ appears to be even tighter than the observed $\pm 1\,\sigma$ (dashed black). The same is true for the NMAD, which is even lower over the same interval.

In the upper panel of Figure~\ref{fig:mzr}, we present the scatter in both predicted and \cite{Tremonti2004} MZR binned by mass. We confirm that the CNN predicts a MZR that is at most equal in scatter than one constructed using the true metallicity. The stellar mass bins for which our CNN found tighter scatter than the empirical MZR are the same bins that happen to contain the greatest number of examples ($9.5 \leq \log (M_{\star, \rm true}/\msol) \leq 10.5$); thus, the strong performance of our network at those masses may be due to a wealth of training examples. If our data set were augmented to include additional low- and high-$M_{\rm \star,true}$ galaxies, then the scatter in the predicted MZR could be even lower overall.

The fact that a CNN trained on only \sdssg\sdssr\sdssi\ imaging is able to predict metallicity accurately enough to reproduce the MZR in terms of median and scatter is not trivial. The error budget is very small: $\sigma = 0.10$~dex affords only, \eg, 0.05~dex of scatter when SFR is a controlled parameter plus a 0.03~dex systematic scatter in $Z_{\rm true}$ measurements, leaving only $\sim 0.08$~dex remaining for CNN systematics, assuming that these errors are not correlated and are added in quadrature. This remaining error budget may barely be able to accommodate our result of RMSE($\Delta Z$) $= 0.085$.
Interpreting the MZR scatter as the combination of intrinsic FMR scatter, $Z_{\rm true}$ systematics, and $\Delta Z$ systematics cannot be correct since it assumes that the CNN is recovering the FMR perfectly.
As we have discussed previously, it is highly unlikely that the CNN is sensitive to the SFR, and therefore cannot probe the MZR at individual values of the SFR.

If we assume that the error budget for the MZR is not determined by the FMR, then the error ``floor'' should be $0.10$~dex.
This is immediately exceeded, as we have found RMSE $\approx 0.10$~dex for the predicted MZR without accounting for the fact that $Z_{\rm pred}$ and $Z_{\rm true}$ differ by RMSE $= 0.085$~dex!
Consider the case in which all $Z_{\rm true}$ values are shifted randomly by a Gaussian noise distribution with $\sigma = 0.085$~dex.
These shifted values should not be able to reconstruct a correlation without introducing additional scatter unless the shifts were not arbitrary to begin with.

We thus find more evidence that the CNN has learned something from the SDSS \sdssg\sdssr\sdssi\ imaging that is different from, but at least as powerful as, the MZR. One possible explination is that the CNN is measuring some version of metallicity that is more fundamentally linked to the stellar mass, rather than $Z_{\rm pred}$ as derived from oxygen spectral lines. Another possibility is that the MZR is a projection of a correlation between stellar mass, metallicity, and a third parameter, perhaps one that is morphological in nature. If this is the case, then the \cite{Tremonti2004} MZR represents a relationship that is randomly distributed in the yet unknown third parameter, while our CNN would be able to stratify the MZR according to this parameter (much as the FMR does with the SFR). We are unfortunately not able to identify any hidden parameter using the current CNN methodology, but we plan to explore this topic in a future work.

\section{Summary}\label{sec:summary}
We have trained a deep convolutional neural network (CNN) to predict galaxy gas-phase metallicity using only $128 \times 128$-pixel, three-band (\sdssg\sdssr\sdssi), JPG images obtained from SDSS. We characterize CNN performance by measuring scatter in the residuals between predicted ($Z_{\rm pred}$) and true ($Z_{\rm true}$) metallicities.
Our conclusions are as follows:

\begin{enumerate}
	\item By training for a half-hour on a GPU, the CNN can predict metallicity well enough to achieve residuals characterized by RMSE $= 0.085$~dex (or outlier-insensitive NMAD $= 0.067$~dex). These findings may be promising for future large spectroscopy-limited surveys such as LSST.

	\item We find that the residual scatter decreases in an expected way as resolution is increased, suggesting that the CNN is leveraging the spatial information about a galaxy's light distribution in order to predict metallicity.

	\item The CNN outperforms a random forest trained on $gri$ photometry if provided images larger than $4\times 4$ pixels, and is as accurate as a random forest trained on $ugriz$ photometry when given $128 \times 128$ pixel \sdssg\sdssr\sdssi\ images.

	\item We find that scatter in the mass-metallicity relation (MZR) constructed using CNN-predicted metallicities is as tight as the empirical MZR ($\sigma = 0.10$~dex).	Because predicted metallicities differ from the ``true'' metallicities by RMSE $= 0.085$~dex, the only way that the predicted MZR can have such low scatter is if the CNN has learned a connection to metallicity that is more strongly linked to the galaxies' light distributions than their nebular line emission.
\end{enumerate}

%An future extension to our work might be to repeat our analysis but to instead train on simulated data.
%A future extension to our work is to try predicting on Dark Energy Survey or CANDELS images.
%Another is to train on five-band imaging and see if we can beat the FMR.
%We can also train CNNs individually on each mass bin and see if indeed we can predict metallicity as accurately.


\section*{Acknowledgements}

SB is supported by NSF Astronomy and Astrophysics Research Program award number 1615657.
The authors thank Andrew Baker, John Hughes, and Eric Gawiser for helpful comments and discussions, and also thank David Shih and Matthew Buckley for the use of their GPU cluster at Rutgers University High Energy Experimental Physics department. %, and Kartheik Iyer for providing SED fits as benchmark as well as for valuable discussion.
JW thanks Jeremy Howard, Rachel Thomas, and the development team for creating the \texttt{fastai} on-line courses and deep learning library.\footnote{\url{https://github.com/fastai/fastai}}
JW also thanks Florian Peter for valuable assistance with using the \texttt{fastai} library.
This research made use of the {\tt IPython} package \citep{Perez2007} and {\tt matplotlib}, a Python library for publication quality graphics \citep{Hunter2007}.

Funding for the Sloan Digital Sky Survey IV has been provided by the Alfred P. Sloan Foundation, the U.S. Department of Energy Office of Science, and the Participating Institutions. SDSS-IV acknowledges
support and resources from the Center for High-Performance Computing at
the University of Utah. The SDSS web site is \url{www.sdss.org}.

SDSS-IV is managed by the Astrophysical Research Consortium for the
Participating Institutions of the SDSS Collaboration including the
Brazilian Participation Group, the Carnegie Institution for Science,
Carnegie Mellon University, the Chilean Participation Group, the French Participation Group, Harvard-Smithsonian Center for Astrophysics,
Instituto de Astrof\'isica de Canarias, The Johns Hopkins University,
Kavli Institute for the Physics and Mathematics of the Universe (IPMU) /
University of Tokyo, the Korean Participation Group, Lawrence Berkeley National Laboratory,
Leibniz Institut f\"ur Astrophysik Potsdam (AIP),
Max-Planck-Institut f\"ur Astronomie (MPIA Heidelberg),
Max-Planck-Institut f\"ur Astrophysik (MPA Garching),
Max-Planck-Institut f\"ur Extraterrestrische Physik (MPE),
National Astronomical Observatories of China, New Mexico State University,
New York University, University of Notre Dame,
Observat\'ario Nacional / MCTI, The Ohio State University,
Pennsylvania State University, Shanghai Astronomical Observatory,
United Kingdom Participation Group,
Universidad Nacional Aut\'onoma de M\'exico, University of Arizona,
University of Colorado Boulder, University of Oxford, University of Portsmouth,
University of Utah, University of Virginia, University of Washington, University of Wisconsin,
Vanderbilt University, and Yale University.

%%%%%%%%%%%%%%%%%%%% REFERENCES %%%%%%%%%%%%%%%%%%
% The best way to enter references is to use BibTeX:
\bibliographystyle{mnras}
%\bibliography{bibliography,boada-bib} % if your bibtex file is called example.bib

\begin{thebibliography}{}
\makeatletter
\relax
\def\mn@urlcharsother{\let\do\@makeother \do\$\do\&\do\#\do\^\do\_\do\%\do\~}
\def\mn@doi{\begingroup\mn@urlcharsother \@ifnextchar [ {\mn@doi@}
  {\mn@doi@[]}}
\def\mn@doi@[#1]#2{\def\@tempa{#1}\ifx\@tempa\@empty \href
  {http://dx.doi.org/#2} {doi:#2}\else \href {http://dx.doi.org/#2} {#1}\fi
  \endgroup}
\def\mn@eprint#1#2{\mn@eprint@#1:#2::\@nil}
\def\mn@eprint@arXiv#1{\href {http://arxiv.org/abs/#1} {{\tt arXiv:#1}}}
\def\mn@eprint@dblp#1{\href {http://dblp.uni-trier.de/rec/bibtex/#1.xml}
  {dblp:#1}}
\def\mn@eprint@#1:#2:#3:#4\@nil{\def\@tempa {#1}\def\@tempb {#2}\def\@tempc
  {#3}\ifx \@tempc \@empty \let \@tempc \@tempb \let \@tempb \@tempa \fi \ifx
  \@tempb \@empty \def\@tempb {arXiv}\fi \@ifundefined
  {mn@eprint@\@tempb}{\@tempb:\@tempc}{\expandafter \expandafter \csname
  mn@eprint@\@tempb\endcsname \expandafter{\@tempc}}}

\bibitem[\protect\citeauthoryear{Abolfathi et~al.,}{Abolfathi
  et~al.}{2018}]{Abolfathi2017}
Abolfathi B.,  et~al., 2018, \mn@doi [\apjs] {10.3847/1538-4365/aa9e8a}, 235, 42

\bibitem[\protect\citeauthoryear{Ackermann, Schawinski, Zhang, Weigel  \&
  Turp}{Ackermann et~al.}{2018}]{Ackermann2018}
Ackermann S.,  Schawinski K.,  Zhang C.,  Weigel A.~K.,   Turp M.~D.,  2018,
  \mn@doi [\mnras]
  {10.1093/mnras/sty1398}, 479, 415

\bibitem[\protect\citeauthoryear{Acquaviva}{Acquaviva}{2016}]{Acquaviva2016}
Acquaviva V.,  2016, \mn@doi [\mnras] {10.1093/mnras/stv2703}, 456, 1618

\bibitem[\protect\citeauthoryear{{Bailer-Jones}}{{Bailer-Jones}}{2000}]{2000A&A...357..197B}
{Bailer-Jones} C.~A.~L.,  2000, \aap, \href
  {http://adsabs.harvard.edu/abs/2000A%26A...357..197B} {357, 197}

\bibitem[\protect\citeauthoryear{Beck et~al.,}{Beck et~al.}{2018}]{Beck2018}
Beck M.~R.,  et~al., 2018, \mn@doi [\mnras] {10.1093/mnras/sty503}, 476, 5516

\bibitem[\protect\citeauthoryear{Brinchmann, Charlot, White, Tremonti,
  Kauffmann, Heckman  \& Brinkmann}{Brinchmann et~al.}{2004}]{Brinchmann2004}
Brinchmann J.,  Charlot S.,  White S. D.~M.,  Tremonti C.,  Kauffmann G.,
  Heckman T.,   Brinkmann J.,  2004, \mn@doi [\mnras] {10.1111/j.1365-2966.2004.07881.x}, 351, 1151

\bibitem[\protect\citeauthoryear{{Brooks}, {Governato}, {Booth}, {Willman},
  {Gardner}, {Wadsley}, {Stinson}  \& {Quinn}}{{Brooks}
  et~al.}{2007}]{Brooks2007}
{Brooks} A.~M.,  {Governato} F.,  {Booth} C.~M.,  {Willman} B.,  {Gardner}
  J.~P.,  {Wadsley} J.,  {Stinson} G.,   {Quinn} T.,  2007, \mn@doi [\apjl]
  {10.1086/511765}, \href {http://adsabs.harvard.edu/abs/2007ApJ...655L..17B}
  {655, L17}

\bibitem[\protect\citeauthoryear{Dahlen et~al.,}{Dahlen
  et~al.}{2013}]{Dahlen2013}
Dahlen T.,  et~al., 2013, \mn@doi [\apj]
  {10.1088/0004-637X/775/2/93}, 775, 93

\bibitem[\protect\citeauthoryear{Dai \& Tong}{Dai \& Tong}{2018}]{Dai2018}
Dai J.-M.,  Tong J.,  2018, preprint (\mn@eprint {arXiv} {1807.05657})

\bibitem[\protect\citeauthoryear{{Dalcanton}, {Yoachim}  \&
  {Bernstein}}{{Dalcanton} et~al.}{2004}]{Dalcanton2004}
{Dalcanton} J.~J.,  {Yoachim} P.,   {Bernstein} R.~A.,  2004, \mn@doi [\apj]
  {10.1086/386358}, \href {http://adsabs.harvard.edu/abs/2004ApJ...608..189D}
  {608, 189}

\bibitem[\protect\citeauthoryear{{Dav{\'e}}, {Finlator}  \&
  {Oppenheimer}}{{Dav{\'e}} et~al.}{2012}]{Dave2012}
{Dav{\'e}} R.,  {Finlator} K.,   {Oppenheimer} B.~D.,  2012, \mn@doi [\mnras]
  {10.1111/j.1365-2966.2011.20148.x}, \href
  {http://adsabs.harvard.edu/abs/2012MNRAS.421...98D} {421, 98}

\bibitem[\protect\citeauthoryear{Dieleman, Willett  \& Dambre}{Dieleman
  et~al.}{2015}]{Dieleman2015}
Dieleman S.,  Willett K.~W.,   Dambre J.,  2015, \mn@doi [\mnras] {10.1093/mnras/stv632}, 450, 1441

\bibitem[\protect\citeauthoryear{Fabbro, Venn, O'Briain, Bialek, Kielty,
  Jahandar  \& Monty}{Fabbro et~al.}{2018}]{Fabbro2018}
Fabbro S.,  Venn K.~A.,  O'Briain T.,  Bialek S.,  Kielty C.~L.,  Jahandar F.,
   Monty S.,  2018, \mn@doi [\mnras]
  {10.1093/mnras/stx3298}, 475, 2978

\bibitem[\protect\citeauthoryear{{Freedman} \& {Diaconis}}{{Freedman} \&
  {Diaconis}}{1981}]{Freedman1981}
{Freedman} D.,  {Diaconis} P.,  1981, {Zeitschrift f{\"u}r
  Wahrscheinlichkeitstheorie und Verwandte Gebiete}, 57, 453

\bibitem[\protect\citeauthoryear{{Garnett}}{{Garnett}}{2002}]{2002ApJ...581.1019G}
{Garnett} D.~R.,  2002, \mn@doi [\apj] {10.1086/344301}, \href
  {http://adsabs.harvard.edu/abs/2002ApJ...581.1019G} {581, 1019}

\bibitem[\protect\citeauthoryear{{He}, {Zhang}, {Ren}  \& {Sun}}{{He}
  et~al.}{2015}]{He2015}
{He} K.,  {Zhang} X.,  {Ren} S.,   {Sun} J.,  2015, preprint, \href
  {http://adsabs.harvard.edu/abs/2015arXiv151203385H} {} (\mn@eprint {arXiv}
  {1512.03385})

\bibitem[\protect\citeauthoryear{{Hezaveh}, {Levasseur}  \&
  {Marshall}}{{Hezaveh} et~al.}{2017}]{Hezaveh2017}
{Hezaveh} Y.~D.,  {Levasseur} L.~P.,   {Marshall} P.~J.,  2017, \mn@doi [\nat]
  {10.1038/nature23463}, \href
  {http://adsabs.harvard.edu/abs/2017Natur.548..555H} {548, 555}

\bibitem[\protect\citeauthoryear{{Hinton}, {Srivastava}, {Krizhevsky},
  {Sutskever}  \& {Salakhutdinov}}{{Hinton} et~al.}{2012}]{dropout}
{Hinton} G.~E.,  {Srivastava} N.,  {Krizhevsky} A.,  {Sutskever} I.,
  {Salakhutdinov} R.~R.,  2012, preprint, \href
  {http://adsabs.harvard.edu/abs/2012arXiv1207.0580H} {} (\mn@eprint {arXiv}
  {1207.0580})

\bibitem[\protect\citeauthoryear{Hocking, Geach, Sun  \& Davey}{Hocking
  et~al.}{2018}]{Hocking2018}
Hocking A.,  Geach J.~E.,  Sun Y.,   Davey N.,  2018, \mn@doi [\mnras] {10.1093/mnras/stx2351}, 473, 1108

\bibitem[\protect\citeauthoryear{{Hopkins} et~al.,}{{Hopkins}
  et~al.}{2003}]{Hopkins2003}
{Hopkins} A.~M.,  et~al., 2003, \mn@doi [\apj] {10.1086/379608}, \href
  {http://adsabs.harvard.edu/abs/2003ApJ...599..971H} {599, 971}

\bibitem[\protect\citeauthoryear{Howard et~al.}{Howard et~al.}{2018}]{fastai}
Howard J.,  et~al., 2018, fastai, \url{https://github.com/fastai/fastai}

\bibitem[\protect\citeauthoryear{Huertas-Company et~al.,}{Huertas-Company
  et~al.}{2015}]{Huertas-Company2015}
Huertas-Company M.,  et~al., 2015, \mn@doi [\apjs] {10.1088/0067-0049/221/1/8}, 221, 8

\bibitem[\protect\citeauthoryear{Huertas-Company et~al.,}{Huertas-Company
  et~al.}{2018}]{Huertas-Company2018}
Huertas-Company M.,  et~al., 2018, \mn@doi [\apj]
  {10.3847/1538-4357/aabfed}, 858, 114

\bibitem[\protect\citeauthoryear{Hunter}{Hunter}{2007}]{Hunter2007}
Hunter J.~D.,  2007, \mn@doi [Computing in Science {\&} Engineering]
  {10.1109/MCSE.2007.55}, 9, 90

\bibitem[\protect\citeauthoryear{Ilbert et~al.,}{Ilbert
  et~al.}{2009}]{Ilbert2009}
Ilbert O.,  et~al., 2009, \mn@doi [\apj]
  {10.1088/0004-637X/690/2/1236}, 690, 1236

\bibitem[\protect\citeauthoryear{{Ioffe} \& {Szegedy}}{{Ioffe} \&
  {Szegedy}}{2015}]{batchnorm}
{Ioffe} S.,  {Szegedy} C.,  2015, preprint, \href
  {http://adsabs.harvard.edu/abs/2015arXiv150203167I} {} (\mn@eprint {arXiv}
  {1502.03167})

\bibitem[\protect\citeauthoryear{Kauffmann et~al.,}{Kauffmann
  et~al.}{2003}]{Kauffmann2003a}
Kauffmann G.,  et~al., 2003, \mn@doi [\mnras] {10.1046/j.1365-8711.2003.06291.x}, 341, 33

\bibitem[\protect\citeauthoryear{Kim \& Brunner}{Kim \&
  Brunner}{2017}]{Kim2017}
Kim E.~J.,  Brunner R.~J.,  2017, \mn@doi [\mnras] {10.1093/mnras/stw2672}, 464, 4463

\bibitem[\protect\citeauthoryear{Kingma \& Ba}{Kingma \& Ba}{2014}]{Kingma2014}
Kingma D.~P.,  Ba J.,  2014, arXiv preprint arXiv:1412.6980

\bibitem[\protect\citeauthoryear{Krizhevsky, Sutskever  \& Hinton}{Krizhevsky
  et~al.}{2012}]{Krizhevsky2012}
Krizhevsky A.,  Sutskever I.,   Hinton G.~E.,  2012, \mn@doi [Proceedings of
  the 25th International Conference on Neural Information Processing Systems -
  Volume 1] {10.1145/3065386}, 60, 1097

\bibitem[\protect\citeauthoryear{Krogh \& Hertz}{Krogh \&
  Hertz}{1992}]{Krogh1992}
Krogh A.,  Hertz J.~A.,  1992, in Advances in neural information processing
  systems. pp 950--957

\bibitem[\protect\citeauthoryear{{Kroupa}}{{Kroupa}}{2001}]{Kroupa2001}
{Kroupa} P.,  2001, \mn@doi [\mnras] {10.1046/j.1365-8711.2001.04022.x}, \href
  {https://ui.adsabs.harvard.edu/#abs/2001MNRAS.322..231K} {322, 231}

\bibitem[\protect\citeauthoryear{{LSST Dark Energy Science
  Collaboration}}{{LSST Dark Energy Science Collaboration}}{2012}]{LSST2012}
{LSST Dark Energy Science Collaboration} 2012, arXiv preprint arXiv:1211.0310,
  p.~133

\bibitem[\protect\citeauthoryear{Lanusse, Ma, Li, Collett, Li, Ravanbakhsh,
  Mandelbaum  \& P{\'{o}}czos}{Lanusse et~al.}{2018}]{Lanusse2017}
Lanusse F.,  Ma Q.,  Li N.,  Collett T.~E.,  Li C.-L.,  Ravanbakhsh S.,
  Mandelbaum R.,   P{\'{o}}czos B.,  2018, \mn@doi [\mnras] {10.1093/mnras/stx1665}, 473, 3895

\bibitem[\protect\citeauthoryear{LeCun, Boser, Denker, Henderson, Howard,
  Hubbard  \& Jackel}{LeCun et~al.}{1989}]{LeCun1989}
LeCun Y.,  Boser B.,  Denker J.~S.,  Henderson D.,  Howard R.~E.,  Hubbard W.,
   Jackel L.~D.,  1989, \mn@doi [Neural Computation]
  {10.1162/neco.1989.1.4.541}, 1, 541

\bibitem[\protect\citeauthoryear{{Leitner} \& {Kravtsov}}{{Leitner} \&
  {Kravtsov}}{2011}]{2011ApJ...734...48L}
{Leitner} S.~N.,  {Kravtsov} A.~V.,  2011, \mn@doi [\apj]
  {10.1088/0004-637X/734/1/48}, \href
  {http://adsabs.harvard.edu/abs/2011ApJ...734...48L} {734, 48}

\bibitem[\protect\citeauthoryear{{Lilly}, {Carollo}, {Pipino}, {Renzini}  \&
  {Peng}}{{Lilly} et~al.}{2013}]{2013ApJ...772..119L}
{Lilly} S.~J.,  {Carollo} C.~M.,  {Pipino} A.,  {Renzini} A.,   {Peng} Y.,
  2013, \mn@doi [\apj] {10.1088/0004-637X/772/2/119}, \href
  {https://ui.adsabs.harvard.edu/#abs/2013ApJ...772..119L} {772, 119}

\bibitem[\protect\citeauthoryear{{Loshchilov} \& {Hutter}}{{Loshchilov} \&
  {Hutter}}{2016}]{SGDR}
{Loshchilov} I.,  {Hutter} F.,  2016, preprint, \href
  {http://adsabs.harvard.edu/abs/2016arXiv160803983L} {} (\mn@eprint {arXiv}
  {1608.03983})

\bibitem[\protect\citeauthoryear{Loshchilov \& Hutter}{Loshchilov \&
  Hutter}{2017}]{Loshchilov2017}
Loshchilov I.,  Hutter F.,  2017, arXiv preprint arXiv:1711.05101

\bibitem[\protect\citeauthoryear{Lupton, Blanton, Fekete, Hogg, O'Mullane,
  Szalay  \& Wherry}{Lupton et~al.}{2004}]{Lupton2004}
Lupton R.,  Blanton M.~R.,  Fekete G.,  Hogg D.~W.,  O'Mullane W.,  Szalay A.,
   Wherry N.,  2004, \mn@doi [\pasp] {10.1086/382245}, 116, 133

\bibitem[\protect\citeauthoryear{Mannucci, Cresci, Maiolino, Marconi  \&
  Gnerucci}{Mannucci et~al.}{2010}]{Mannucci2010}
Mannucci F.,  Cresci G.,  Maiolino R.,  Marconi A.,   Gnerucci A.,  2010,
  \mn@doi [\mnras]
  {10.1111/j.1365-2966.2010.17291.x}, 408, 2115

\bibitem[\protect\citeauthoryear{Molino et~al.,}{Molino
  et~al.}{2017}]{Molino2017}
Molino A.,  et~al., 2017, \mn@doi [\mnras] {10.1093/mnras/stx1243}, 470, 95

\bibitem[\protect\citeauthoryear{Nair \& Hinton}{Nair \&
  Hinton}{2010}]{Nair2010}
Nair V.,  Hinton G.~E.,  2010, in Proceedings of the 27th International
  Conference on International Conference on Machine Learning. ICML'10.
Omnipress, USA, pp 807--814, \url
  {http://dl.acm.org/citation.cfm?id=3104322.3104425}

\bibitem[\protect\citeauthoryear{Ntampaka, Trac, Sutherland, Battaglia,
  P{\'{o}}czos  \& Schneider}{Ntampaka et~al.}{2015}]{Ntampaka2015}
Ntampaka M.,  Trac H.,  Sutherland D.~J.,  Battaglia N.,  P{\'{o}}czos B.,
  Schneider J.,  2015, \mn@doi [\apj]
  {10.1088/0004-637X/803/2/50}, 803, 50

\bibitem[\protect\citeauthoryear{Ntampaka, Trac, Cisewski  \& Price}{Ntampaka
  et~al.}{2017}]{Ntampaka2016}
Ntampaka M.,  Trac H.,  Cisewski J.,   Price L.~C.,  2017, \mn@doi [The
  Astrophysical Journal] {10.3847/1538-4357/835/1/106}, 835, 106

\bibitem[\protect\citeauthoryear{Oke}{Oke}{1974}]{Oke1974}
Oke J.~B.,  1974, \mn@doi [\apjs]
  {10.1086/190287}, 27, 21

\bibitem[\protect\citeauthoryear{Pan \& Yang}{Pan \& Yang}{2010}]{Pan2010}
Pan S.~J.,  Yang Q.,  2010, \mn@doi [IEEE Trans. on Knowl. and Data Eng.]
  {10.1109/TKDE.2009.191}, 22, 1345

\bibitem[\protect\citeauthoryear{Paszke et~al.,}{Paszke et~al.}{2017}]{pytorch}
Paszke A.,  et~al., 2017, in NIPS-W.

\bibitem[\protect\citeauthoryear{Pedregosa et~al.,}{Pedregosa
  et~al.}{2012}]{Pedregosa2012}
Pedregosa F.,  et~al., 2012, Journal of Machine Learning Research, 12, 2825

\bibitem[\protect\citeauthoryear{Perez \& Granger}{Perez \&
  Granger}{2007}]{Perez2007}
Perez F.,  Granger B.~E.,  2007, \mn@doi [Computing in Science {\&}
  Engineering] {10.1109/MCSE.2007.53}, 9, 21

\bibitem[\protect\citeauthoryear{Petrillo et~al.,}{Petrillo
  et~al.}{2017}]{Petrillo2017}
Petrillo C.~E.,  et~al., 2017, \mn@doi [\mnras] {10.1093/mnras/stx2052}, 472, 1129

\bibitem[\protect\citeauthoryear{Petrillo et~al.,}{Petrillo
  et~al.}{2018}]{Petrillo2018}
Petrillo C.~E.,  et~al., 2018, eprint arXiv:1807.04764

\bibitem[\protect\citeauthoryear{Petrosian}{Petrosian}{1976}]{Petrosian1976}
Petrosian V.,  1976, \mn@doi [\apj] {10.1086/182253}, 209,
  L1

\bibitem[\protect\citeauthoryear{{Russakovsky} et~al.,}{{Russakovsky}
  et~al.}{2014}]{ImageNet}
{Russakovsky} O.,  et~al., 2014, preprint, \href
  {http://adsabs.harvard.edu/abs/2014arXiv1409.0575R} {} (\mn@eprint {arXiv}
  {1409.0575})

\bibitem[\protect\citeauthoryear{Salim et~al.,}{Salim et~al.}{2007}]{Salim2007}
Salim S.,  et~al., 2007, \mn@doi [\apjs]
  {10.1086/519218}, 173, 267

\bibitem[\protect\citeauthoryear{{S{\'a}nchez} et~al.,}{{S{\'a}nchez}
  et~al.}{2013}]{2013A&A...554A..58S}
{S{\'a}nchez} S.~F.,  et~al., 2013, \mn@doi [\aap]
  {10.1051/0004-6361/201220669}, \href
  {http://adsabs.harvard.edu/abs/2013A%26A...554A..58S} {554, A58}

\bibitem[\protect\citeauthoryear{Scherer, M{\"u}ller  \& Behnke}{Scherer
  et~al.}{2010}]{Scherer2010}
Scherer D.,  M{\"u}ller A.,   Behnke S.,  2010, in , Artificial Neural
  Networks--ICANN 2010.
Springer, pp 92--101

\bibitem[\protect\citeauthoryear{{Simmons} et~al.,}{{Simmons}
  et~al.}{2017}]{2017MNRAS.464.4420S}
{Simmons} B.~D.,  et~al., 2017, \mn@doi [\mnras] {10.1093/mnras/stw2587}, \href
  {http://adsabs.harvard.edu/abs/2017MNRAS.464.4420S} {464, 4420}

\bibitem[\protect\citeauthoryear{{Simonyan} \& {Zisserman}}{{Simonyan} \&
  {Zisserman}}{2014}]{2014arXiv1409.1556S}
{Simonyan} K.,  {Zisserman} A.,  2014, preprint, \href
  {http://adsabs.harvard.edu/abs/2014arXiv1409.1556S} {} (\mn@eprint {arXiv}
  {1409.1556})

\bibitem[\protect\citeauthoryear{Smirnov \& Markov}{Smirnov \&
  Markov}{2017}]{Smirnov2017}
Smirnov E.~A.,  Markov A.~B.,  2017, \mn@doi [\mnras] {10.1093/mnras/stx999}, 469, 2024

\bibitem[\protect\citeauthoryear{{Smith}}{{Smith}}{2015}]{CLR}
{Smith} L.~N.,  2015, preprint, \href
  {http://adsabs.harvard.edu/abs/2015arXiv150601186S} {} (\mn@eprint {arXiv}
  {1506.01186})

\bibitem[\protect\citeauthoryear{{The Dark Energy Survey Collaboration}}{{The
  Dark Energy Survey Collaboration}}{2005}]{DES2005}
{The Dark Energy Survey Collaboration} 2005, eprint arXiv:astro-ph/0510346,
  p.~42

\bibitem[\protect\citeauthoryear{Tremonti et~al.,}{Tremonti
  et~al.}{2004}]{Tremonti2004}
Tremonti C.~A.,  et~al., 2004, \mn@doi [\apj]
  {10.1086/423264}, 613, 898

\bibitem[\protect\citeauthoryear{Xu, Ho, Trac, Schneider, Poczos  \&
  Ntampaka}{Xu et~al.}{2013}]{Xu2013}
Xu X.,  Ho S.,  Trac H.,  Schneider J.,  Poczos B.,   Ntampaka M.,  2013,
  \mn@doi [\apj] {10.1088/0004-637X/772/2/147}, 772, 147

\bibitem[\protect\citeauthoryear{York et~al.,}{York et~al.}{2000}]{York2000}
York D.~G.,  et~al., 2000, \mn@doi [\aj] {10.1086/301513},
  120, 1579

\bibitem[\protect\citeauthoryear{Zeiler \& Fergus}{Zeiler \&
  Fergus}{2014}]{Zeiler2014}
Zeiler M.~D.,  Fergus R.,  2014, in Fleet D.,  Pajdla T.,  Schiele B.,
  Tuytelaars T.,  eds, Computer Vision -- ECCV 2014. Springer, Cham, Cham, pp
  818--833, \mn@doi{10.1007/978-3-319-10590-1_53}, \url
  {http://link.springer.com/10.1007/978-3-319-10590-1{\_}53}

\makeatother
\end{thebibliography}


%%%%%%%%%%%%%%%%% APPENDICES %%%%%%%%%%%%%%%%%%%%%
\appendix
%
\section{Convolution neural network details}

\subsection{Residual neural network architecture}
CNNs are divided into ``layers'' that compute the convolutions of filters, or kernels, with each of the inputs.
A Rectified Linear Unit (ReLU) activation function is applied to the convolved output \citep[ReLUs have been shown to propagate information about the relative importances of different features, and are effective for training deep neural networks;][]{Nair2010}.
In a residual CNN, multiple convolutional layers containing small (e.g., $3\times 3$) filters are arranged sequentially, and a final ``shortcut connection'' adds the first layer, unaltered, to the final output \citep[before the final ReLU activation; see, e.g., Figure~2 of][]{He2015}.
Such combinations of convolutions, activations, and shortcuts are called residual building blocks.

We use a 34-layer residual convolutional neural network with the architecture described by \cite{He2015}, and implemented using \texttt{PyTorch} \citep[version 0.3.1;][]{pytorch} provided by the \texttt{fastai} framework \citep[version 0.7;][]{fastai}.
A full description of the architecture's layers can be found in the online \texttt{PyTorch} documentation,\footnote{\url{https://pytorch.org/docs/stable/torchvision/models.html}} but we also provide a brief overview below.

The resnet can be separated into three ``layer groups'' that roughly correspond to the levels of abstraction able to be learned by the network. Once an image is fed into the network, \eg, a three-channel $128\times 128$ SDSS image, it is effectively converted into activation maps that depend on how well the filters match the input image. These maps are further convolved with the next layer of filters, and this process continues until the last layer group is reached. The activation maps are periodically downsampled, max pooled, or average pooled, which effectively halve the map sizes in each spatial dimension \citep[for more about pooling layers in CNNs, see][]{Scherer2010}. The first two layer groups comprise multiple residual building blocks, and the final layer group consists of two fully connected linear layers, with a ReLU activation after the first and no activation after the second. The last fully connected layer does not have an activation function because we are working on a regression problem, and so the weights trained in that layer should be tuned to predict metallicity in the desired range.

\subsection{Adaptive learning rates}
Neural network performance tends to depend dramatically on choice of hyperparameters. After an image is fed forward and the residual (= prediction $-$ true) value is computed, relative contributions of error are propagated backward through the network, starting from the final layer and ending at the first layer. Using gradient descent of the loss (in our case, the root mean squared error), the network layers' weights are adjusted according to their error contributions multiplied by the \textit{learning rate}. The process of computing errors from known images and metallicities and updating weights is called \textit{training}, and when all of the training data set has been used to adjust network weights, a training \textit{epoch} is completed.

The learning rate can be thought of as the step size during each weight update. A high learning rate allows the network to improve quickly, but at some point the large step size may become too coarse for additional optimization; conversely, a low learning rate might allow the network to traverse every bump and wiggle in the error landscape, but might also take a very long time to reach convergence (or get stuck indefinitely in a local minimum). We first select a learning rate by using the method described by \cite{CLR}. Over a number of epochs, the learning rate is reduced (or \textit{annealed}) as the network needs to make more fine-tuned updates in order to achieve better accuracy. We use a method called cosine annealing, during which the learning rate is annealed with the cosine function continuously over individual (or batches of) training examples.
It has been shown that if the learning rate is annealed and then restarted after one or more epochs, the network is less likely to get caught in local minima and overall accuracy is improved. We refer to \cite{SGDR} for details about employing cyclical learning rates and gradient descent with restarts, which are implemented in our CNN.

\subsection{Optimization techniques and preventing overfitting} \label{sec:optimization}

Losses are computed for small ``batches'' of training examples at a time. Gradients that minimize each batch are expected to be noisier than gradients that are computed to optimize the entire training data set loss. This technique of \textit{stochastic gradient descent} helps prevent the CNN from overfitting training data, which is a possibility given the huge number of parameters in a deep CNN. We also use weight decay, another commonly used regularization technique, which adds a decay term proportional to each layer weight during the update step of training \citeeg{Krogh1992}.

As the learning rate is annealed with increasing numbers of batches, the weight updates are also expected to diminish.
The Adam optimizer adaptively smooths the gradient descent in a way that depends on previous gradients \citep{Kingma2014}.
Adam is analogous to rolling downhill with gravitational potential, momentum, and friction terms (whereas gradient descent would be analogous to movement dependent only on the potential at its given time step).
For caveats about combining weight decay and Adam, see \cite{Loshchilov2017}, whose updated algorithm is implemented in \texttt{fastai}.

We implement batch normalization (BN), a technique developed to fix a problem that previously caused deep networks to train extremely slowly \citep{batchnorm}. To briefly recap the issue: updates to the layer weights depend on the contribution of the backpropagated error, but when the number of layers is large (\ie, in a deep CNN), the contribution becomes vanishingly small. BN is simply the rescaling of each input to the nonlinear activation so that it has mean of zero and standard deviation of unity (\ie, subtract the mean and divide by the standard deviation). A new choice of hyperparameter is the batch size, or the number of training examples from which the mean and variance are calculated); we choose 256 based on tests of performance in ten training epochs.

Dropout is a method of disabling a random subset of connections after linear layers in a network in order to improve the network's generalizability \citep{dropout}. The ensemble of learned gradients is less prone to overfit the training data set because the network is forced to discard random (and potentially valuable) information. The resulting network is better able to, \eg, learn subtle differences in the data that would otherwise be ignored when more obvious features dominate the gradient descent process. We apply dropout layers only to the final fully connected layers in our deep CNN, and avoid dropout in the batch-normalized layers \citep[as recommended by][]{batchnorm}. We use dropout rates of 0.25 for the linear layer after the early group, and 0.50 at the later linear layer, both of which are \texttt{fastai} defaults.

\subsection{Training the network}
We initialize the network using weights that have been pretrained on the 1.7~million example ImageNet data set \citep[which contains 1000 classes of objects;][]{ImageNet}. The network should more quickly optimize toward the global minimum loss through transfer of low-level features already learned in earlier layers of the network \citep[known as transfer learning; see, \eg,][]{Pan2010}.

We train only the final layer group for the first two epochs, which can be accomplished by not updating weights in the first two layer groups. The learning rate is initially set to 0.1 and then annealed according to a cosine schedule over an epoch (and then restarted to 0.1 at the beginning of the following epoch). We then allow the updating of weights in all layer groups while setting the learning rates to 0.001, 0.01, and 0.01 for the first, second, and last layer groups, respectively. This approach allows the final group of fully connected layers to respond strongly to different types of training examples (\eg, galaxies that appear very different in \sdssg\sdssr\sdssi\ imaging) while the earlier layers are trained very slowly in order to preserve their more general features. Using these layered learning rates, we train the full network using a cosine annealing schedule that spans one, one, two, and then four epochs (where the different learning rates are annealed by the same amount). Using this combination of learning rate schedules, we find that our network quickly achieves low training losses (RMSE $\sim 0.085$ on validation data sets). Altogether, only ten epochs of training are needed, which takes under 30 minutes on a GPU. We find that further training does yield some gains, but this improvement plateaus around RMSE $\sim 0.083$ and takes many more hours.

\subsection{Data augmentation}\label{sec:data aug}
Nearly all neural networks benefit from larger training samples because they help prevent overfitting. Beyond the local Universe, galaxies are seen at nearly random orientation; such invariance permits synthetic data to be generated from rotations and flips of the training images \citep[see, \eg,][]{2014arXiv1409.1556S}. Each image is fed into the network along with four augmented versions, thus increasing the total training sample by a factor of five.

This technique is called data augmentation, and is particularly helpful for the network to learn uncommon truth values (\eg, in our case, very metal-poor or metal-rich galaxies). Each augmented image is fed-forward through the network and gradient contributions are computed together as part of the same batch. A similar process is applied to the network during predictions, which is known as test-time augmentation (TTA), whereby synthetic images are generated according to the same rules applied to the training data set. The CNN predicts an ensemble average over the augmented images, which tends to further improve RMSE by a few percent. We use the default hyperparameters in the \texttt{fastai} library.

% Don't change these lines
\bsp	% typesetting comment
\label{lastpage}
\end{document}
